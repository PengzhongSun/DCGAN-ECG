{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fvZB7guTO4JL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import CIFAR10\n",
    "# from pylab import plt\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOrmIHmuP4Ld"
   },
   "source": [
    "OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_AOtw9owPG4T"
   },
   "outputs": [],
   "source": [
    "# 输入为一维行向量\n",
    "def one_hot(x,mu=256): # 1*250\n",
    "  hot = np.zeros((mu,x.shape[0]))\n",
    "  for i in np.arange(x.shape[0]):\n",
    "      hot[x[i],i]=1\n",
    "  return hot     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LU2y2JNQAPG"
   },
   "source": [
    "Encode & Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZzPUFu5qPnEl"
   },
   "outputs": [],
   "source": [
    "def encode_mu_law(x, mu=256):\n",
    "    mu = mu-1\n",
    "    fx = np.sign(x)*np.log(1+mu*np.abs(x))/np.log(1+mu)\n",
    "    return np.floor((fx+1)/2*mu+0.5).astype(np.long)\n",
    "\n",
    "def decode_mu_law(y, mu=256):  \n",
    "    mu = mu-1\n",
    "    fx = (y-0.5)/mu*2-1\n",
    "    x = np.sign(fx)/mu*((1+mu)**np.abs(fx)-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o7iSeDEqevto"
   },
   "source": [
    "Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8KcHvtK5ibiC"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  f = h5py.File(\"drive/DCGAN-ECG/ecg_data.h5\",'r')\n",
    "  ecg_train = f['ecg_train']\n",
    "  ecg_test = f['ecg_test']\n",
    "  return ecg_train,ecg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706.0
    },
    "colab_type": "code",
    "id": "o08VBD-71Otj",
    "outputId": "92342ab1-4607-496b-a275-4f2666dd1513"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e19b3080ee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 读取数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mecg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mecg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(ecg_train[:10,:10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c00e78601b63>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/DCGAN-ECG/ecg_data.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mecg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ecg_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mecg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ecg_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mecg_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mecg_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'drive/DCGAN-ECG/ecg_data.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "mu=64\n",
    "# 读取数据\n",
    "ecg_train,ecg_test = load_data()\n",
    "# print(ecg_train[:10,:10])\n",
    "\n",
    "# 数据编码\n",
    "y = encode_mu_law(ecg_train[:,:64],mu=mu)    # 每个样本只取前64个样本点\n",
    "plt.plot(y[0][:])\n",
    "# print(y.shape)\n",
    "# print(y[:10,:10])\n",
    "\n",
    "# onehot编码\n",
    "hot_y = np.zeros((y.shape[0],mu,y.shape[1]))  # 实例个数*mu*采样点个数\n",
    "for i in np.arange(hot_y.shape[0]):\n",
    "  hot_y[i] = one_hot(y[i][:],mu = mu)\n",
    "\n",
    "# print(hot_y.shape)\n",
    "# print(hot_y[:5,:10,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272.0
    },
    "colab_type": "code",
    "id": "KCxYztwa1Zzw",
    "outputId": "68fd224a-7dd0-43c8-9398-2a22b98e27b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "--2018-12-12 00:34:28--  https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
      "Resolving launchpad.net (launchpad.net)... 91.189.89.222, 91.189.89.223\n",
      "Connecting to launchpad.net (launchpad.net)|91.189.89.222|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2018-12-12 00:34:30 ERROR 404: Not Found.\n",
      "\n",
      "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb': No such file or directory\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
      "··········\n",
      "/bin/bash: google-drive-ocamlfuse: command not found\n"
     ]
    }
   ],
   "source": [
    "# 授权验证\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
    "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
    "!apt-get install -f\n",
    "!apt-get -y install -qq fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vef3doz81ZdQ"
   },
   "outputs": [],
   "source": [
    "# 指定Google Drive云端硬盘的根目录，名为drive\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUMpz_qbtjbD"
   },
   "source": [
    "DCGAN config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LOevPOiJtfyD"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    lr = 0.0002 #learning rate\n",
    "    nz = 100 # noise dimension\n",
    "    image_size = 64\n",
    "    image_size2 = 64 \n",
    "    nc = 1 # chanel of img \n",
    "    ngf = 64 # generate channel\n",
    "    ndf = 64 # discriminative channel\n",
    "    beta1 = 0.5\n",
    "    batch_size = 64  \n",
    "#     max_epoch = 10 # =1 when debug\n",
    "    max_epoch = 100 # =1 when debug\n",
    "    workers = 2  #加载数据的子进程数，0时只有主进程\n",
    "    gpu = True  # use gpu or not\n",
    "    \n",
    "opt=Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlbHLJ4xX_kb"
   },
   "source": [
    "make_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HqW82xMtI0ZA"
   },
   "outputs": [],
   "source": [
    "def make_tensor():\n",
    "  y = hot_y.reshape(hot_y.shape[0],-1,hot_y.shape[1],hot_y.shape[2])\n",
    "  # z=np.concatenate((y,y,y),axis=1)              # 单通道到三通道\n",
    "  data = t.from_numpy(y/1.)\n",
    "\n",
    "  \n",
    "  torch_data = t.utils.data.TensorDataset(data,data)  #target不重要，没有用\n",
    "  dataloader = t.utils.data.DataLoader(torch_data,opt.batch_size,shuffle=True,num_workers=opt.workers)  \n",
    "  return dataloader\n",
    "\n",
    "# make_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9H-kIaMYA_0"
   },
   "source": [
    "demake_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GOBvf3j9YDuf"
   },
   "outputs": [],
   "source": [
    "# torch.Size([32, 3, 64, 64])\n",
    "def demake_tensor(x):\n",
    "#   y = x.numpy()\n",
    "  y = x.detach().cpu().numpy()\n",
    "  N = y.shape[0]\n",
    "  mu = y.shape[2]\n",
    "  num_nodes = y.shape[3]\n",
    "#   z = np.sum(y,axis=1) \n",
    "  z = y.reshape(N,mu,-1)\n",
    "  assert z.shape==(N,mu,num_nodes),\"dimension is wrong.\"\n",
    "#   return z/3.\n",
    "  return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMVLbJpyS4Ve"
   },
   "source": [
    "find_maximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ILrUohb-TCah"
   },
   "outputs": [],
   "source": [
    "# (num ,mu , num_nodes) --> (num , num_nodes)\n",
    "def find_maximal(x):\n",
    "  N = x.shape[0]\n",
    "  num_nodes = x.shape[2]\n",
    "  prob = np.zeros((N,1,num_nodes))\n",
    "  prob = np.max(x,axis=1)\n",
    "  return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-I0nZWIIfFvQ"
   },
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "klxbDIlzeq8K"
   },
   "outputs": [],
   "source": [
    "netg = nn.Sequential(\n",
    "    nn.ConvTranspose2d(opt.nz,opt.ngf*8,4,1,0,bias=False),  \n",
    "    nn.BatchNorm2d(opt.ngf*8),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(opt.ngf*8,opt.ngf*4,4,2,1,bias=False),\n",
    "    nn.BatchNorm2d(opt.ngf*4),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(opt.ngf*4,opt.ngf*2,4,2,1,bias=False),\n",
    "    nn.BatchNorm2d(opt.ngf*2),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(opt.ngf*2,opt.ngf,4,2,1,bias=False),\n",
    "    nn.BatchNorm2d(opt.ngf),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(opt.ngf,opt.nc,4,2,1,bias=False),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWuSsPnxfNxz"
   },
   "source": [
    "Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yI6CJOnJfIhM"
   },
   "outputs": [],
   "source": [
    "netd = nn.Sequential(\n",
    "    nn.Conv2d(opt.nc,opt.ndf,4,2,1,bias=False),\n",
    "    nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "    nn.Conv2d(opt.ndf,opt.ndf*2,4,2,1,bias=False),\n",
    "    nn.BatchNorm2d(opt.ndf*2),\n",
    "    nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "    nn.Conv2d(opt.ndf*2,opt.ndf*4,4,2,1,bias=False),\n",
    "    nn.BatchNorm2d(opt.ndf*4),\n",
    "    nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "    nn.Conv2d(opt.ndf*4,opt.ndf*8,4,2,1,bias=False),\n",
    "    nn.BatchNorm2d(opt.ndf*8),\n",
    "    nn.LeakyReLU(0.2,inplace=True),\n",
    "\n",
    "    nn.Conv2d(opt.ndf*8,1,4,1,0,bias=False),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIoOYVJafbqK"
   },
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1sO1gEK7fYhC"
   },
   "outputs": [],
   "source": [
    "# optimizerD = Adam(netd.parameters(),lr=opt.lr,betas=(opt.beta1,0.999))\n",
    "# optimizerG = Adam(netg.parameters(),lr=opt.lr,betas=(opt.beta1,0.999))\n",
    "\n",
    "optimizerD = Adam(netd.parameters(),lr=opt.lr,betas=(opt.beta1,0.5))   # 论文建议0.5\n",
    "optimizerG = Adam(netg.parameters(),lr=opt.lr,betas=(opt.beta1,0.5))\n",
    "\n",
    "# criterion\n",
    "criterion = nn.BCELoss()    # compute loss\n",
    "\n",
    "fix_noise = Variable(t.FloatTensor(opt.batch_size,opt.nz,1,1).normal_(0,1))\n",
    "if opt.gpu:\n",
    "    fix_noise = fix_noise.cuda()\n",
    "    netd.cuda()\n",
    "    netg.cuda()\n",
    "    criterion.cuda() # it's a good habit ，使用cuda计算损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UgSstjLfjLJ"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SB2GibhDfiGJ"
   },
   "outputs": [],
   "source": [
    "# begin training\n",
    "dataloader = make_tensor()\n",
    "\n",
    "print('Start training......')\n",
    "\n",
    "loss_D = np.zeros(opt.max_epoch)\n",
    "loss_G = np.zeros(opt.max_epoch)\n",
    "\n",
    "for epoch in range(opt.max_epoch):\n",
    "    for ii,data in enumerate(dataloader,0):  # ii is step\n",
    "#         print(\"Tringing.....\")\n",
    "        real,_ = data\n",
    "        input = Variable(real)  # batch_size,channels,width,height\n",
    "        label = Variable(t.ones(input.size(0))) # 1 for real\n",
    "        noise = t.randn(input.size(0),opt.nz,1,1)  # opt.nz=100\n",
    "        noise = Variable(noise)\n",
    "        \n",
    "        if opt.gpu:\n",
    "            noise = noise.cuda()\n",
    "            input = input.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        # ----- train netd -----\n",
    "        netd.zero_grad()\n",
    "        ## train netd with real img    \n",
    "        ## Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "        output=netd(input.float())  \n",
    "        error_real=criterion(output.squeeze(),label)    \n",
    "        error_real.backward()\n",
    "        D_x=output.data.mean()\n",
    "        ## train netd with fake img\n",
    "        fake_pic=netg(noise).detach()\n",
    "        output2=netd(fake_pic)\n",
    "        label.data.fill_(0) # 0 for fake\n",
    "        error_fake=criterion(output2.squeeze(),label)\n",
    "        error_fake.backward()\n",
    "        D_x2=output2.data.mean()\n",
    "        error_D=error_real+error_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # ------ train netg -------\n",
    "        netg.zero_grad()\n",
    "        label.data.fill_(1)\n",
    "        noise.data.normal_(0,1)\n",
    "        fake_pic=netg(noise)\n",
    "        output=netd(fake_pic)\n",
    "        error_G=criterion(output.squeeze(),label)\n",
    "        error_G.backward()\n",
    "        optimizerG.step()\n",
    "        D_G_z2=output.data.mean()\n",
    "        \n",
    "        loss_D[epoch]+=error_D.data[0]\n",
    "        loss_G[epoch]+=error_G.data[0] \n",
    "        \n",
    "    if epoch % 20 ==0:\n",
    "        print(\"epoch=\",epoch)\n",
    "#         print('{epoch}  lossD:{loss_D},lossG:{loss_G}'.format(\n",
    "#                epoch=epoch,loss_D=loss_D,loss_G=loss_G))\n",
    "        fake_u=netg(fix_noise)\n",
    "        img1 = demake_tensor(fake_u)\n",
    "        img2 = find_maximal(img1)\n",
    "        ecg = decode_mu_law(img2,64)\n",
    "        print(ecg[0,:5])\n",
    "        plt.plot(ecg[0,:])        \n",
    "        plt.show()\n",
    "        \n",
    "plt.plot(loss_D,'r--',label=\"Discriminator\")\n",
    "plt.plot(loss_D,'b--',label=\"Generator\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"How Loss Changed\")\n",
    "plt.lengend(loc=\"upper left\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3idnYuCUNjoU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2AvnLEXvLeEf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN-ECG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
